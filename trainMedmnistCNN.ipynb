{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfbb5b57",
   "metadata": {},
   "source": [
    "# Applying MedMnist data to a convolutional neural network with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "831616a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset ,DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor , Lambda\n",
    "import pandas as pd\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "import medmnist\n",
    "import numpy as np\n",
    "from medmnist import INFO, Evaluator\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from medmnist import INFO, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "830e20e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medmnist.evaluator.Evaluator"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ac4531",
   "metadata": {},
   "source": [
    "### In this notebook we going to learn how to preprocess a dataset and feed it to a cnn with pytorch \n",
    "#### it a Binary Classification with Two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9ebf4fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medmnist version : 2.2.3\n"
     ]
    }
   ],
   "source": [
    "print(f'medmnist version : {medmnist.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "19ede39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python_class': 'BreastMNIST',\n",
       " 'description': 'The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.',\n",
       " 'url': 'https://zenodo.org/record/6496656/files/breastmnist.npz?download=1',\n",
       " 'MD5': '750601b1f35ba3300ea97c75c52ff8f6',\n",
       " 'task': 'binary-class',\n",
       " 'label': {'0': 'malignant', '1': 'normal, benign'},\n",
       " 'n_channels': 1,\n",
       " 'n_samples': {'train': 546, 'val': 78, 'test': 156},\n",
       " 'license': 'CC BY 4.0'}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_flag = 'breastmnist'\n",
    "download = True\n",
    "info=INFO[data_flag]\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ddf855f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 546, 'val': 78, 'test': 156}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['n_samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "305bad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "def extractdata(data):\n",
    " # Load the .npz archive\n",
    " loaded_data = np.load(data)\n",
    "\n",
    " # Access non-array files (if any)\n",
    " # Note: Files other than NumPy arrays are not directly accessible via numpy.load\n",
    "\n",
    " # Specify the destination folder for extracted files\n",
    " destination_folder = os.getcwd()\n",
    "\n",
    " with zipfile.ZipFile(data) as archive:\n",
    "    # List the files in the archive\n",
    "    file_list = archive.namelist()\n",
    "\n",
    "    # Extract each file from the archive to the destination folder\n",
    "    for file_name in file_list:\n",
    "        archive.extract(file_name, destination_folder)\n",
    "        extracted_file_path = os.path.join(destination_folder, file_name)\n",
    "        print(f\"Extracted: {extracted_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "575c3a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: /home/sanaa/PHD/fedsim/train_images.npy\n",
      "Extracted: /home/sanaa/PHD/fedsim/val_images.npy\n",
      "Extracted: /home/sanaa/PHD/fedsim/test_images.npy\n",
      "Extracted: /home/sanaa/PHD/fedsim/train_labels.npy\n",
      "Extracted: /home/sanaa/PHD/fedsim/val_labels.npy\n",
      "Extracted: /home/sanaa/PHD/fedsim/test_labels.npy\n"
     ]
    }
   ],
   "source": [
    "data=os.path.join('/home/sanaa/.medmnist/','breastmnist.npz')\n",
    "extractdata(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2566903",
   "metadata": {},
   "source": [
    "#### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cd111664",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrainpath=os.path.join(os.getcwd(),'train_labels.npy')\n",
    "xtrainpath=os.path.join(os.getcwd(),'train_images.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "612311c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sanaa/PHD/fedsim/train_images.npy'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrainpath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad03b62",
   "metadata": {},
   "source": [
    "#### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e9801b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtestpath=os.path.join(os.getcwd(),'test_images.npy')\n",
    "ytestpath=os.path.join(os.getcwd(),'test_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8ce1d5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert labels to hot encoded\n",
    "#encoder = OneHotEncoder(sparse=False)\n",
    "#target = encoder.fit_transform(np.load(ytrainpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8be953a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTorch(xdata,ydata):\n",
    "    #conveert numpy data to tensor\n",
    "    xdata=np.load(xdata)\n",
    "    \n",
    "    xdata_=torch.from_numpy(xdata).float()\n",
    "    #xdata_/= 255.0\n",
    "    ydata_=torch.from_numpy(np.load(ydata))\n",
    "\n",
    "    return xdata_,ydata_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ee49470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data features\n",
    "#conveert numpy data to tensor\n",
    "xtrain,ytrain=convertTorch(xtrainpath,ytrainpath)\n",
    "xtest,ytest=convertTorch(xtestpath,ytestpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f65da305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input train shape torch.Size([546, 28, 28]) , and input label shape : torch.Size([156, 28, 28])\n",
      "output train shape: torch.Size([156, 1]) and out label shape : torch.Size([156, 1])\n"
     ]
    }
   ],
   "source": [
    "#print(f'inputs images of training dataset : {xtrain[0]}')\n",
    "print(f' input train shape {xtrain.shape} , and input label shape : {xtest.shape}')\n",
    "print(f'output train shape: {ytest.shape} and out label shape : {ytest.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "773b86b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training dataset\n",
    "train_dataset=TensorDataset(xtrain,ytrain)\n",
    "#test dataset\n",
    "test_dataset=TensorDataset(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "66a2f7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e55025f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "examples = next(iter(train_dataloader))\n",
    "#examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1e6c8e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([64, 28, 28])\n",
      "torch.Size([34, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for batch, (X, y) in enumerate(train_dataloader):\n",
    "    print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0364e87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "#crrate a NN basic Model \n",
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "58a4456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizing model parameters\n",
    "## we need a loss function and an optmizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2a503f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple CNN model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 16, kernel_size=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(16, 64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 4 * 4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "n_channels=1\n",
    "n_classes=1\n",
    "modelh = Net(in_channels=n_channels, num_classes=n_classes)\n",
    "modelh.to(device)    \n",
    "# define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "lr = 0.001    \n",
    "optimizer = optim.SGD(modelh.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c85a4c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        X = X.unsqueeze(1)  # Adds a channel dimension at position 1 \n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        #y = y.view(-1, 1)\n",
    "        loss = loss_fn(pred, y.float())\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "66bd9d88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            X = X.unsqueeze(1)  # Adds a channel dimension at position 1 \n",
    "            y=y.float()\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            test_loss /= num_batches\n",
    "            #print(pred)\n",
    "        print(\"Accuracy: \", ((pred > 0.0) == y).float().mean().item())   \n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fc8e6153",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.702764  [   64/  546]\n",
      "Accuracy:  0.2857142984867096\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.668159  [   64/  546]\n",
      "Accuracy:  0.785714328289032\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.600523  [   64/  546]\n",
      "Accuracy:  0.7500000596046448\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.624808  [   64/  546]\n",
      "Accuracy:  0.785714328289032\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.627794  [   64/  546]\n",
      "Accuracy:  0.7142857313156128\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.450490  [   64/  546]\n",
      "Accuracy:  0.6071428656578064\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.465524  [   64/  546]\n",
      "Accuracy:  0.785714328289032\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.470156  [   64/  546]\n",
      "Accuracy:  0.7142857313156128\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.407338  [   64/  546]\n",
      "Accuracy:  0.6785714626312256\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.533230  [   64/  546]\n",
      "Accuracy:  0.8571429252624512\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.418471  [   64/  546]\n",
      "Accuracy:  0.6428571939468384\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.410353  [   64/  546]\n",
      "Accuracy:  0.7500000596046448\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.438916  [   64/  546]\n",
      "Accuracy:  0.7500000596046448\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.442316  [   64/  546]\n",
      "Accuracy:  0.7142857313156128\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.431575  [   64/  546]\n",
      "Accuracy:  0.785714328289032\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.424779  [   64/  546]\n",
      "Accuracy:  0.785714328289032\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.425278  [   64/  546]\n",
      "Accuracy:  0.6785714626312256\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.431183  [   64/  546]\n",
      "Accuracy:  0.7500000596046448\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.438026  [   64/  546]\n",
      "Accuracy:  0.8214285969734192\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.396598  [   64/  546]\n",
      "Accuracy:  0.8214285969734192\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.533150  [   64/  546]\n",
      "Accuracy:  0.8571429252624512\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.477113  [   64/  546]\n",
      "Accuracy:  0.7500000596046448\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.471333  [   64/  546]\n",
      "Accuracy:  0.785714328289032\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.371958  [   64/  546]\n",
      "Accuracy:  0.785714328289032\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.407348  [   64/  546]\n",
      "Accuracy:  0.8214285969734192\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.308535  [   64/  546]\n",
      "Accuracy:  0.785714328289032\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.378680  [   64/  546]\n",
      "Accuracy:  0.8571429252624512\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.345994  [   64/  546]\n",
      "Accuracy:  0.8214285969734192\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.328229  [   64/  546]\n",
      "Accuracy:  0.8571429252624512\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.321314  [   64/  546]\n",
      "Accuracy:  0.785714328289032\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, modelh, criterion, optimizer)\n",
    "    test(test_dataloader, modelh, criterion)\n",
    "print(\"Done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38631eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
